{"cells":[{"metadata":{"_uuid":"81170eaf-e042-42c7-ac23-8cf8a397218a","_cell_guid":"10425b9f-1653-4670-ad67-d84f5d517782","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Titanic data Modelling**"},{"metadata":{},"cell_type":"markdown","source":"* This notebook is focus on applying algorithm to the train and test data.\n* For the EDA part is located on another notebook\n* Algorithmn I used :\n    1. XGBoost\n    2. SVC"},{"metadata":{},"cell_type":"markdown","source":"# Import required libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/titanic/train.csv')\ndf_test = pd.read_csv('/kaggle/input/titanic/test.csv')\ntrain = df_train.copy()\ntest = df_test.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Features details**\n* survival : Survival\t0 = No, 1 = Yes\n* pclass : Ticket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n* sex\t: Sex\t\n* Age\t: Age in years\t\n* sibsp\t: # of siblings / spouses aboard the Titanic\t\n* parch\t: # of parents / children aboard the Titanic\t\n* ticket\t: Ticket number\t\n* fare\t: Passenger fare\t\n* cabin\t: Cabin number\t\n* embarked\t: Port of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n\n**Variable Notes**\n* pclass: A proxy for socio-economic status (SES)\n* 1st = Upper\n* 2nd = Middle\n* 3rd = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way\n* Sibling = brother, sister, stepbrother, stepsister\n* Spouse = husband, wife (mistresses and fianc√©s were ignored)\n\nparch: The dataset defines family relations in this way...\n* Parent = mother, father\n* Child = daughter, son, stepdaughter, stepson\n* Some children travelled only with a nanny, therefore parch=0 for them."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train data','\\n')\nprint(train.info(),'\\n')\nprint(train.describe(),'\\n')\n\nprint('Test data','\\n')\nprint(test.info(),'\\n')\nprint(test.describe(),'\\n')\n\nprint('Train data : {}'.format(train.shape))\nprint('Test data : {}'.format(test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Manipulation and Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def col_counts(col):\n    '''Print the value counts of columns from train and test data.'''\n    if col in train.columns:\n        print('Train\\'s {} : '.format(col))\n        print(train[col].value_counts(),'\\n')\n    else:\n        print('Train\\'s data does not have {} column.'.format(col))\n        \n    if col in test.columns:\n        print('Test\\'s {} : '.format(col))\n        print(test[col].value_counts())\n    else:\n        print('Test\\'s data does not have {} column.'.format(col))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Drop Passenger Id and Ticket's columns**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def drop_col(data, column):\n    return data.drop(column, inplace = True,axis = 1)\n\ndrop_col(train, ['PassengerId', 'Ticket'])\ndrop_col(test, ['PassengerId', 'Ticket'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Survived**"},{"metadata":{"trusted":true},"cell_type":"code","source":"col_counts('Survived')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Name**"},{"metadata":{},"cell_type":"markdown","source":"**Extract the title from the name of passenger**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Title'] = train.Name.apply(lambda x : x.split(',')[1].split('.')[0].strip())\ntest['Title'] = test.Name.apply(lambda x : x.split(',')[1].split('.')[0].strip())\n\ndef title_type(row):\n    if row in ['Don', 'Mme',\n       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess',\n       'Jonkheer','Dona','Dr','Rev']:\n        # label as rare for titles that are low in counts\n        return 'Rare'\n    elif row == 'Miss':\n        return 'Ms'\n    else:\n        return row\n    \ntrain['Title'] = train.Title.apply(title_type)\ntest['Title'] = test.Title.apply(title_type)\n\ndrop_col(train, 'Name')\ndrop_col(test,'Name')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_counts('Title')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Sex**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Sex'] = train.Sex.map({'male':'Male','female':'Female'})\ntest['Sex'] = test.Sex.map({'male':'Male','female':'Female'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_counts('Sex')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Family**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Family'] = train.SibSp + train.Parch + 1\ntest['Family'] = test.SibSp + test.Parch + 1\ndrop_col(train, ['SibSp','Parch'])\ndrop_col(test, ['SibSp','Parch'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_counts('Family')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Family_type'] = pd.cut(train.Family, [0,1,4,7,11], labels = ['Single', 'Small', 'Medium', 'Large'])\ntest['Family_type'] = pd.cut(test.Family, [0,1,4,7,11], labels = ['Single', 'Small', 'Medium', 'Large'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_counts('Family_type')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Age**"},{"metadata":{},"cell_type":"markdown","source":"Divide into 3 stage : Child, Adult, Elderly"},{"metadata":{"trusted":true},"cell_type":"code","source":"def age_diff(row):\n    if row < 18:\n        return 'Child'\n    elif (row < 60) & (row >=18):\n        return 'Adult'\n    else:\n        return 'Elderly'\n\ntrain['Age_cat'] = train.Age.apply(age_diff)\ntest['Age_cat'] = test.Age.apply(age_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_counts('Age_cat')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cabin**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Cabin_floor'] = train.Cabin.apply(lambda x: list(str(x))[0])\ntrain['Cabin_floor'] = train.Cabin_floor.replace('n', np.nan)\n\ntest['Cabin_floor'] = test.Cabin.apply(lambda x: list(str(x))[0])\ntest['Cabin_floor'] = test.Cabin_floor.replace('n', np.nan)\n\ndrop_col(train,'Cabin')\ndrop_col(test,'Cabin')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_counts('Cabin_floor')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, RobustScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import plot_tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import VotingClassifier\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\n\nseed = 225","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['Survived']\nX = train.drop('Survived',axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**XG with Age as categorical**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# define columns for numerical and categorical\nnum_cols = ['Fare']\n\ncat_cols = ['Pclass', 'Sex','Embarked','Title','Family_type','Age_cat']\n\n# pipeline for preprocessing of numerical and categorical data\ncat_transformer = Pipeline(steps = [('Cat_Imputer', SimpleImputer(strategy = 'most_frequent')),('OneHotEncoder',OneHotEncoder(handle_unknown = 'ignore'))])\nnum_transformer = Pipeline(steps = [('Num_Imputer', SimpleImputer(strategy = 'median'))])\n\npreprocessor = ColumnTransformer(transformers = [('num', num_transformer, num_cols), ('cat',cat_transformer, cat_cols)])\n\n# pipeline for modeling\ntitanic_pipeline = Pipeline(steps = [('Preprocessor',preprocessor),('XG', XGBClassifier(random_state = seed))])\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = seed)\n\nparams = {'XG__learning_rate' : [0.1,0.2], 'XG__gamma' : [0.001,0.01,1,10],'XG__max_depth' : [4,6,8,10], 'XG__n_estimators' : [400,500]}\n\nsearcher = GridSearchCV(titanic_pipeline,params, cv = 3, verbose = 1, n_jobs = -1 )\n\nsearcher.fit(X_train,y_train)\n\nprint('Best params : {}'.format(searcher.best_params_))\nprint('Best score : {:.2f}'.format(searcher.best_score_))\n\ny_pred_train = searcher.predict(X_train)\ny_pred_test = searcher.predict(X_test)\n\nprint('XGBoost\\'s train score : {:.3f}'.format(accuracy_score(y_train,y_pred_train)))\nprint('XGBoost\\'s test score : {:.3f}'.format(accuracy_score(y_test,y_pred_test)))\nprint(confusion_matrix(y_test, y_pred_test))\nprint(classification_report(y_test,y_pred_test))\nprint('XGBoost\\'s roc score : {:.3f}'.format(roc_auc_score(y_test,y_pred_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**XG with Age as numerical**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# define columns for numerical and categorical\nnum_cols = ['Fare','Age']\n\ncat_cols = ['Pclass', 'Sex','Embarked','Title','Family_type']\n\n# pipeline for preprocessing of numerical and categorical data\ncat_transformer = Pipeline(steps = [('Cat_Imputer', SimpleImputer(strategy = 'most_frequent')),('OneHotEncoder',OneHotEncoder(handle_unknown = 'ignore'))])\nnum_transformer = Pipeline(steps = [('Num_Imputer', SimpleImputer(strategy = 'median'))])\n\npreprocessor = ColumnTransformer(transformers = [('num', num_transformer, num_cols), ('cat',cat_transformer, cat_cols)])\n\n# pipeline for modeling\ntitanic_pipeline = Pipeline(steps = [('Preprocessor',preprocessor),('XG', XGBClassifier(random_state = seed, learning_rate = 0.1))])\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = seed)\n\nparams = { 'XG__gamma' : [0.001,0.01,1,10,100,1000],'XG__max_depth' : [2,4,6,8,10], 'XG__n_estimators' : [400,500]}\n\nsearcher_xg = GridSearchCV(titanic_pipeline,params, cv = 3, verbose = 1, n_jobs = -1 )\n\nsearcher_xg.fit(X_train,y_train)\n\nprint('Best params : {}'.format(searcher_xg.best_params_))\nprint('Best score : {:.2f}'.format(searcher_xg.best_score_))\n\ny_pred_train = searcher_xg.predict(X_train)\ny_pred_test = searcher_xg.predict(X_test)\n\nprint('XGBoost\\'s train score : {:.3f}'.format(accuracy_score(y_train,y_pred_train)))\nprint('XGBoost\\'s test score : {:.3f}'.format(accuracy_score(y_test,y_pred_test)))\nprint(confusion_matrix(y_test, y_pred_test))\nprint(classification_report(y_test,y_pred_test))\nprint('XGBoost\\'s roc score : {:.3f}'.format(roc_auc_score(y_test,y_pred_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SVC with Age as categorical**"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = ['Fare']\n\ncat_cols = ['Pclass', 'Sex','Embarked','Title','Family_type','Age_cat']\n\ncat_transformer = Pipeline(steps = [('Cat_Imputer', SimpleImputer(strategy = 'most_frequent')),('OneHotEncoder',OneHotEncoder(handle_unknown = 'ignore'))])\nnum_transformer = Pipeline(steps = [('Num_Imputer', SimpleImputer(strategy = 'median')), ('Scaler', RobustScaler())])\n\npreprocessor = ColumnTransformer(transformers = [('num', num_transformer, num_cols), ('cat',cat_transformer, cat_cols)])\n\ntitanic_pipeline = Pipeline(steps = [('Preprocessor',preprocessor),('SVC', SVC(random_state = seed))])\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = seed)\n\nparameters = {'SVC__C':[0.1, 1, 10,100], 'SVC__gamma':[ 0.001, 0.01, 0.1,1,10]}\nsearcher = GridSearchCV(titanic_pipeline, parameters, cv = 5, n_jobs = -1, verbose = 1)\n\nsearcher.fit(X_train,y_train)\n\nprint('Best params : {}'.format(searcher.best_params_))\nprint('Best score : {:.2f}'.format(searcher.best_score_))\n\ny_pred_train = searcher.predict(X_train)\ny_pred_test = searcher.predict(X_test)\n\nprint('SVC\\'s train score : {:.3f}'.format(accuracy_score(y_train,y_pred_train)))\nprint('SVC\\'s test score : {:.3f}'.format(accuracy_score(y_test,y_pred_test)))\nprint(confusion_matrix(y_test, y_pred_test))\nprint(classification_report(y_test,y_pred_test))\nprint('SVC\\'s roc score : {:.3f}'.format(roc_auc_score(y_test,y_pred_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Applying model on test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"output = searcher_xg.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['Survived'] = output\ndf_test = df_test[['PassengerId', 'Survived']]\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.to_csv('submission_2.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}